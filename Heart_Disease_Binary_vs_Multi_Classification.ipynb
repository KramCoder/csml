{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease Prediction: Multi-class vs Binary Classification Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import sys\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f'python version: {sys.version}')\n",
    "print(f'numpy version: {np.__version__}')\n",
    "print(f'pandas version: {pd.__version__}')\n",
    "print(f'tensorflow version: {tf.__version__}')\n",
    "\n",
    "# To get more consistent results, try to set the random seed:\n",
    "random.seed(19)\n",
    "np.random.seed(19)\n",
    "tf.random.set_seed(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the heart disease dataset\n",
    "column_names = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','class']\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data', names=column_names)\n",
    "\n",
    "print(\"Original dataset info:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nDataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values from DataFrame\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "# Transform data to numeric because ca and thal are object datatypes\n",
    "data = df.apply(pd.to_numeric)\n",
    "print(\"After preprocessing:\")\n",
    "print(data.dtypes)\n",
    "print(\"\\nDataset shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target classes\n",
    "print(\"Original Multi-class Distribution:\")\n",
    "print(data['class'].value_counts().sort_index())\n",
    "print(\"\\nUnique classes:\", sorted(data['class'].unique()))\n",
    "print(\"Number of classes:\", len(data['class'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and Y datasets for training\n",
    "X = data.iloc[:,0:13]\n",
    "y_multi = data.iloc[:,-1]  # Multi-class target\n",
    "\n",
    "# Create binary classification target\n",
    "# Class 0: No heart disease (0)\n",
    "# Class 1: Any level of heart disease (1, 2, 3, 4 -> 1)\n",
    "y_binary = (y_multi > 0).astype(int)\n",
    "\n",
    "print(\"Binary Classification Distribution:\")\n",
    "print(y_binary.value_counts().sort_index())\n",
    "print(\"\\nBinary classes mapping:\")\n",
    "print(\"0: No heart disease\")\n",
    "print(\"1: Heart disease (any level)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for multi-class classification\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X, y_multi, test_size=0.2, shuffle=False, random_state=90)\n",
    "\n",
    "# One-hot encode for multi-class (5 classes: 0, 1, 2, 3, 4)\n",
    "y_train_multi_cat = to_categorical(y_train_multi, num_classes=5)\n",
    "y_test_multi_cat = to_categorical(y_test_multi, num_classes=5)\n",
    "\n",
    "print(\"Multi-class training data shapes:\")\n",
    "print(f\"X_train: {X_train_multi.shape}\")\n",
    "print(f\"y_train: {y_train_multi_cat.shape}\")\n",
    "print(f\"X_test: {X_test_multi.shape}\")\n",
    "print(f\"y_test: {y_test_multi_cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multi-class model\n",
    "model_multi = Sequential()\n",
    "model_multi.add(Input(shape=(13,)))\n",
    "model_multi.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model_multi.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model_multi.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "model_multi.add(Dense(5, activation='softmax'))  # 5 classes with softmax\n",
    "\n",
    "print(\"Multi-class Model Architecture:\")\n",
    "model_multi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile multi-class model\n",
    "model_multi.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Setup callbacks\n",
    "callbacks_list_multi = [ModelCheckpoint(filepath='best_model_multi.keras', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multi-class model\n",
    "print(\"Training Multi-class Model...\")\n",
    "history_multi = model_multi.fit(X_train_multi, y_train_multi_cat, \n",
    "                                epochs=60, batch_size=8, verbose=1, \n",
    "                                validation_data=(X_test_multi, y_test_multi_cat),\n",
    "                                callbacks=[callbacks_list_multi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for binary classification\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X, y_binary, test_size=0.2, shuffle=False, random_state=90)\n",
    "\n",
    "print(\"Binary classification training data shapes:\")\n",
    "print(f\"X_train: {X_train_binary.shape}\")\n",
    "print(f\"y_train: {y_train_binary.shape}\")\n",
    "print(f\"X_test: {X_test_binary.shape}\")\n",
    "print(f\"y_test: {y_test_binary.shape}\")\n",
    "\n",
    "print(\"\\nBinary target distribution in training set:\")\n",
    "print(pd.Series(y_train_binary).value_counts().sort_index())\n",
    "print(\"\\nBinary target distribution in test set:\")\n",
    "print(pd.Series(y_test_binary).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build binary classification model with same architecture but sigmoid output\n",
    "model_binary = Sequential()\n",
    "model_binary.add(Input(shape=(13,)))\n",
    "model_binary.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model_binary.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model_binary.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "model_binary.add(Dense(1, activation='sigmoid'))  # 1 output with sigmoid for binary classification\n",
    "\n",
    "print(\"Binary Classification Model Architecture:\")\n",
    "model_binary.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile binary model\n",
    "model_binary.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Setup callbacks\n",
    "callbacks_list_binary = [ModelCheckpoint(filepath='best_model_binary.keras', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train binary model\n",
    "print(\"Training Binary Classification Model...\")\n",
    "history_binary = model_binary.fit(X_train_binary, y_train_binary, \n",
    "                                 epochs=60, batch_size=8, verbose=1, \n",
    "                                 validation_data=(X_test_binary, y_test_binary),\n",
    "                                 callbacks=[callbacks_list_binary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Multi-class Model\n",
    "print(\"=== MULTI-CLASS MODEL EVALUATION ===\")\n",
    "pred_multi = model_multi.predict(X_test_multi)\n",
    "y_pred_multi_argmax = np.argmax(pred_multi, axis=1)\n",
    "y_test_multi_argmax = np.argmax(y_test_multi_cat, axis=1)\n",
    "\n",
    "multi_accuracy = accuracy_score(y_test_multi_argmax, y_pred_multi_argmax) * 100\n",
    "print(f'Multi-class Classification Accuracy: {multi_accuracy:.2f}%')\n",
    "print('\\nMulti-class Classification Report:')\n",
    "print(classification_report(y_test_multi_argmax, y_pred_multi_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Binary Model\n",
    "print(\"=== BINARY CLASSIFICATION MODEL EVALUATION ===\")\n",
    "pred_binary = model_binary.predict(X_test_binary)\n",
    "y_pred_binary = (pred_binary > 0.5).astype(int).flatten()\n",
    "\n",
    "binary_accuracy = accuracy_score(y_test_binary, y_pred_binary) * 100\n",
    "print(f'Binary Classification Accuracy: {binary_accuracy:.2f}%')\n",
    "print('\\nBinary Classification Report:')\n",
    "print(classification_report(y_test_binary, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Accuracies\n",
    "print(\"=== ACCURACY COMPARISON ===\")\n",
    "print(f\"Multi-class Classification Accuracy: {multi_accuracy:.2f}%\")\n",
    "print(f\"Binary Classification Accuracy: {binary_accuracy:.2f}%\")\n",
    "print(f\"Difference: {binary_accuracy - multi_accuracy:.2f} percentage points\")\n",
    "\n",
    "if binary_accuracy > multi_accuracy:\n",
    "    print(\"\\nüèÜ WINNER: Binary Classification performs better!\")\n",
    "    print(f\"Binary classification is {binary_accuracy - multi_accuracy:.2f} percentage points more accurate.\")\n",
    "elif multi_accuracy > binary_accuracy:\n",
    "    print(\"\\nüèÜ WINNER: Multi-class Classification performs better!\")\n",
    "    print(f\"Multi-class classification is {multi_accuracy - binary_accuracy:.2f} percentage points more accurate.\")\n",
    "else:\n",
    "    print(\"\\nü§ù TIE: Both models perform equally well!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history comparison\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Multi-class accuracy\n",
    "ax1.plot(history_multi.history['accuracy'], label='Training Accuracy')\n",
    "ax1.plot(history_multi.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Multi-class Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Multi-class loss\n",
    "ax2.plot(history_multi.history['loss'], label='Training Loss')\n",
    "ax2.plot(history_multi.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Multi-class Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Binary accuracy\n",
    "ax3.plot(history_binary.history['accuracy'], label='Training Accuracy')\n",
    "ax3.plot(history_binary.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax3.set_title('Binary Model Accuracy')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "# Binary loss\n",
    "ax4.plot(history_binary.history['loss'], label='Training Loss')\n",
    "ax4.plot(history_binary.history['val_loss'], label='Validation Loss')\n",
    "ax4.set_title('Binary Model Loss')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Loss')\n",
    "ax4.legend()\n",
    "ax4.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final accuracy comparison bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = ['Multi-class\\n(5 classes)', 'Binary\\n(2 classes)']\n",
    "accuracies = [multi_accuracy, binary_accuracy]\n",
    "colors = ['skyblue', 'lightcoral']\n",
    "\n",
    "bars = plt.bar(models, accuracies, color=colors, alpha=0.8, edgecolor='black')\n",
    "plt.title('Classification Accuracy Comparison', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Add accuracy values on top of bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             f'{acc:.2f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Multi-class Classification (5 classes): {multi_accuracy:.2f}%\")\n",
    "print(f\"Binary Classification (2 classes): {binary_accuracy:.2f}%\")\n",
    "print(f\"Performance difference: {abs(binary_accuracy - multi_accuracy):.2f} percentage points\")\n",
    "\n",
    "if binary_accuracy > multi_accuracy:\n",
    "    print(f\"\\n‚úÖ Binary classification is MORE ACCURATE by {binary_accuracy - multi_accuracy:.2f} percentage points\")\n",
    "    print(\"\\nPossible reasons for better binary performance:\")\n",
    "    print(\"‚Ä¢ Simpler decision boundary (disease vs no disease)\")\n",
    "    print(\"‚Ä¢ More balanced classes after grouping\")\n",
    "    print(\"‚Ä¢ Reduced complexity eliminates confusion between disease severity levels\")\n",
    "elif multi_accuracy > binary_accuracy:\n",
    "    print(f\"\\n‚úÖ Multi-class classification is MORE ACCURATE by {multi_accuracy - binary_accuracy:.2f} percentage points\")\n",
    "    print(\"\\nPossible reasons for better multi-class performance:\")\n",
    "    print(\"‚Ä¢ Preserves important information about disease severity\")\n",
    "    print(\"‚Ä¢ Model can learn more nuanced patterns\")\n",
    "    print(\"‚Ä¢ Different disease levels have distinct characteristics\")\n",
    "else:\n",
    "    print(\"\\nü§ù Both approaches perform equally well\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}